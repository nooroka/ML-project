{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "i7r8c6N2Af98",
        "outputId": "fc179b66-c1cd-4bce-ee93-01f07b02dd71"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-28a0d2e515a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDictionaryFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MA_PF00754_1_wrong.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-28a0d2e515a7>\u001b[0m in \u001b[0;36mDictionaryFromFile\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mDictionaryFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0meverything\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mreadline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MA_PF00754_1_wrong.txt'"
          ]
        }
      ],
      "source": [
        "def DictionaryFromFile(filename):\n",
        "    with open(filename) as f:\n",
        "        everything = \"\".join(f.readlines()).split(\"\\n\")\n",
        "        result = {}\n",
        "        readline = 0\n",
        "        key = None\n",
        "        value = []\n",
        "        while readline < len(everything):\n",
        "            if len(everything[readline]) == 0:\n",
        "                readline += 1\n",
        "                continue\n",
        "            if everything[readline][0] == '>':\n",
        "                if (key != None):\n",
        "                    result[key] = value\n",
        "                key = everything[readline][1:]\n",
        "                value = []\n",
        "            else:\n",
        "                numbers = everything[readline].split()\n",
        "                added_value = []\n",
        "                for n in numbers:\n",
        "                    added_value.append(float(n))\n",
        "                value.append(added_value)\n",
        "            readline += 1\n",
        "        if (key != None):\n",
        "            result[key] = value\n",
        "        return result \n",
        "\n",
        "#d = DictionaryFromFile(\"MA_PF00754_1_wrong.txt\")\n",
        "#print(d)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torch\n",
        "torch.manual_seed(0)\n"
      ],
      "metadata": {
        "id": "tNxkP4xPOHrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9297130-fa28-4e6e-870d-b83de82bd006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa294f34ab0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_juj39QPrfq",
        "outputId": "eb38c3cc-ff11-4a75-ebf3-bb61bfe66a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mjLP2VIyQDSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_OF_DATAtest= '/content/gdrive/\"My Drive\"/testprob'\n",
        "!ls {PATH_OF_DATAtest}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLW6HjInPxt3",
        "outputId": "bfbbc688-03f7-4f0c-9691-ee7c915fe329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/gdrive/My Drive/testprob': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_OF_DATAtrain= '/content/gdrive/\"My Drive\"/trainprob'\n",
        "!ls {PATH_OF_DATAtrain}"
      ],
      "metadata": {
        "id": "d-YfpyS3P-t4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa39a711-d12c-40ac-c90c-b43f73612922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/gdrive/My Drive/trainprob': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_OF_DATAtest= '/content/gdrive/\"My Drive\"/testprob'\n",
        "!ls {PATH_OF_DATAtest}"
      ],
      "metadata": {
        "id": "MkIHotPXRb2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73efa24c-21de-44b5-97b7-52669cfbcacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/gdrive/My Drive/testprob': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_OF_DATAval= '/content/gdrive/\"My Drive\"/valprob'\n",
        "!ls {PATH_OF_DATAval}"
      ],
      "metadata": {
        "id": "3XYNzRIhRhzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d06f4a40-3b54-4c3d-d488-a348a006833c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/gdrive/My Drive/valprob': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import os\n",
        "class MyDataset(Dataset):\n",
        "   def __init__(self, np_file_paths):\n",
        "        #self.data = torch.FloatTensor(data.values.astype('float'))\n",
        "        self.files = os.listdir(np_file_paths)\n",
        "        self.np_file_paths = np_file_paths\n",
        "   def __getitem__(self, index):\n",
        "     x = np.load(\"{}/{}\".format(self.np_file_paths, self.files[index]))\n",
        "     x = torch.from_numpy(x).float()\n",
        "     return x\n",
        "   def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "        \n",
        "#train_dataset = '/content/gdrive/\"My Drive\"/trainprob'\n",
        "#test_dataset = '/content/gdrive/\"My Drive\"/testprob'\n"
      ],
      "metadata": {
        "id": "xS0mo80DSsV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset =  MyDataset('/content/drive/MyDrive/trainprob/')\n",
        "test_dataset = MyDataset('/content/drive/MyDrive/testprob/')\n",
        "val_dataset = MyDataset('/content/drive/MyDrive/valueprob/')"
      ],
      "metadata": {
        "id": "VWTBRaobPBc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[12]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-sBV1XGUXVA",
        "outputId": "14532406-38b5-41ec-e911-168dce19cdc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 1., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 1., 0.,  ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBxLxxc7UZz5",
        "outputId": "879ea821-bb8e-4139-b0ad-2dfd16e512fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainloader = DataLoader(train_dataset, batch_size = 50)\n",
        "valloader = DataLoader(val_dataset, batch_size = 50)\n",
        "testloader = DataLoader(test_dataset, batch_size = 50)"
      ],
      "metadata": {
        "id": "SCElWTgqSpWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#у меня 22, а не 20\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "class _Model(torch.nn.Module):\n",
        "    \"\"\"A neural network model to predict phylogenetic trees.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Create a neural network model.\"\"\"\n",
        "        super().__init__()\n",
        "        self.conv = torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(88, 88, 1, groups=22),\n",
        "            torch.nn.BatchNorm1d(88),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv1d(88, 32, 1),\n",
        "            torch.nn.BatchNorm1d(32),\n",
        "            torch.nn.ReLU(),\n",
        "            _ResidueModule(32),\n",
        "            _ResidueModule(32),\n",
        "            torch.nn.AvgPool1d(2),\n",
        "            _ResidueModule(32),\n",
        "            _ResidueModule(32),\n",
        "            torch.nn.AvgPool1d(2),\n",
        "            _ResidueModule(32),\n",
        "            _ResidueModule(32),\n",
        "            torch.nn.AvgPool1d(2),\n",
        "            _ResidueModule(32),\n",
        "            _ResidueModule(32),\n",
        "            torch.nn.AdaptiveAvgPool1d(1),\n",
        "        )\n",
        "        self.classifier = torch.nn.Linear(32, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size()[0], 88, -1)\n",
        "        x = self.conv(x).squeeze(dim=2)\n",
        "        return self.classifier(x)\n",
        "class _ResidueModule(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, channel_count):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(channel_count, channel_count, 1),\n",
        "            torch.nn.BatchNorm1d(channel_count),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv1d(channel_count, channel_count, 1),\n",
        "            torch.nn.BatchNorm1d(channel_count),\n",
        "            torch.nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.layers(x)"
      ],
      "metadata": {
        "id": "gpphG2WYOeL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#непонятно, как писать train\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train_epoch(model,\n",
        "                optimizer,\n",
        "                criterion,\n",
        "                train_loader):\n",
        "    loss_history = []\n",
        "    for batch in train_loader: \n",
        "        optimizer.zero_grad()\n",
        "        X_train, Y_train = batch # parse data\n",
        "        X_train, Y_train = X_train.to(device), Y_train.to(device) # compute on gpu\n",
        "        Y_pred = model(X_train) # get predictions\n",
        "        loss = criterion(Y_pred, Y_train) # compute loss\n",
        "        loss_history.append(loss.cpu().detach().numpy()) # write loss to log\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return loss_history\n"
      ],
      "metadata": {
        "id": "7Q3Dy80_yyOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model,\n",
        "             criterion,\n",
        "             val_loader):\n",
        "    cumloss = 0\n",
        "    loss_history = []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            X_train, Y_train = batch # parse data\n",
        "            X_train, Y_train = X_train.to(device), Y_train.to(device) # compute on gpu\n",
        "            Y_pred = model(X_train) # get predictions\n",
        "            loss = criterion(Y_pred, Y_train) # compute loss\n",
        "            loss_history.append(loss.cpu().detach().numpy()) # write loss to log\n",
        "            cumloss += loss\n",
        "    return cumloss / len(val_loader), loss_history # mean loss and history"
      ],
      "metadata": {
        "id": "4B_2eexm1rY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, optimizer, model_name=None, n_epochs=5):\n",
        "  \n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    train_history = {}\n",
        "    train_history['model_name'] = model_name\n",
        "    train_history['loss_on_train'] = []\n",
        "    train_history['loss_on_test'] = []\n",
        "\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        loss_on_train = train_epoch(model,\n",
        "                                    optimizer,\n",
        "                                    criterion,\n",
        "                                    trainloader)\n",
        "        _, loss_on_test = validate(model,\n",
        "                                   criterion,\n",
        "                                   testloader)\n",
        "        train_history['loss_on_train'].extend(loss_on_train)\n",
        "        train_history['loss_on_test'].extend(loss_on_test)\n",
        "    return train_history"
      ],
      "metadata": {
        "id": "Kju6smAb11zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "model = _Model().to(device) \n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "history = train_model(model, optimizer, model_name='n_layers2_sigmoid')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "trUONJxj2LwY",
        "outputId": "74c4ecfb-f7d1-43dc-9a6f-d304dff548d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:13<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-dc777a63a715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'n_layers2_sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-1ac64c72f619>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, model_name, n_epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m                                     \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                     \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                                     trainloader)\n\u001b[0m\u001b[1;32m     17\u001b[0m         _, loss_on_test = validate(model,\n\u001b[1;32m     18\u001b[0m                                    \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-4703f8b5b27d>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, criterion, train_loader)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;31m# parse data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute on gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#видимо, самой писать, а не из статьи\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # change run time to gpu to fast training\n",
        "\n",
        "model = _Model().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "loss_hist = [] # for plotting\n",
        "fast_model = model\n",
        "loss_function = torch.nn.CrossEntropyLoss(reduction='sum')\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "            fast_model.train()\n",
        "            sample_count, score = 0, 0.0\n",
        "            optimizer.zero_grad()\n",
        "            for i, (_a, x, _b, y) in enumerate(train_dataset):\n",
        "                sample_count += x.size()[0]\n",
        "                x = x.to(device, non_blocking=True)\n",
        "                y = y.to(device, non_blocking=True)\n",
        "                loss = loss_function(fast_model(x), y)\n",
        "                loss.backward()\n",
        "                score += float(loss)\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "            fast_model.eval()\n",
        "            \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "YGLY8Yl_XL89",
        "outputId": "f1509877-a03a-4a8c-84ce-0eb9d1136fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-a0c9ad69b5bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfast_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-70366a97c8d0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m88\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[300, 88, -1]' is invalid for input of size 6600"
          ]
        }
      ]
    }
  ]
}